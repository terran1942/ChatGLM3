{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b89f64d8f8053d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
    "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
    "\n",
    "## 硬件需求\n",
    "显存：24GB\n",
    "显卡架构：安培架构（推荐）\n",
    "内存：16GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42937756-6062-4677-ac18-9501154f222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr  7 15:36:45 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.65                 Driver Version: 551.86         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080        On  |   00000000:01:00.0  On |                  N/A |\n",
      "| 30%   42C    P8             16W /  320W |     606MiB /  16376MiB |      3%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        27      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd9a514ed09ea6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. 准备数据集\n",
    "我们使用 AdvertiseGen 数据集来进行微调。从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 AdvertiseGen 数据集，将解压后的 AdvertiseGen 目录放到本目录的 `/data/` 下, 例如。\n",
    "> /media/zr/Data/Code/ChatGLM3/finetune_demo/data/AdvertiseGen\n",
    "\n",
    "接着，运行本代码来切割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T05:52:10.089622Z",
     "start_time": "2024-04-07T05:52:09.268873Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def _mkdir(dir_name: Union[str, Path]):\n",
    "    dir_name = _resolve_path(dir_name)\n",
    "    if not dir_name.is_dir():\n",
    "        dir_name.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
    "    def _convert(in_file: Path, out_file: Path):\n",
    "        _mkdir(out_file.parent)\n",
    "        with open(in_file, encoding='utf-8') as fin:\n",
    "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
    "                for line in fin:\n",
    "                    dct = json.loads(line)\n",
    "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
    "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
    "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    data_dir = _resolve_path(data_dir)\n",
    "    save_dir = _resolve_path(save_dir)\n",
    "\n",
    "    train_file = data_dir / 'train.json'\n",
    "    if train_file.is_file():\n",
    "        out_file = save_dir / train_file.relative_to(data_dir)\n",
    "        _convert(train_file, out_file)\n",
    "\n",
    "    dev_file = data_dir / 'dev.json'\n",
    "    if dev_file.is_file():\n",
    "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
    "        _convert(dev_file, out_file)\n",
    "\n",
    "\n",
    "convert_adgen('data/AdvertiseGen', 'data/AdvertiseGen_fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a4325c-4c88-4fec-8131-fd432c79434e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modelscope in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (1.13.3)\n",
      "Requirement already satisfied: addict in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.4.0)\n",
      "Requirement already satisfied: attrs in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (23.2.0)\n",
      "Requirement already satisfied: datasets>=2.14.5 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.18.0)\n",
      "Requirement already satisfied: einops in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (0.7.0)\n",
      "Requirement already satisfied: filelock>=3.3.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (3.13.3)\n",
      "Requirement already satisfied: gast>=0.2.2 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (0.5.4)\n",
      "Requirement already satisfied: huggingface-hub in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (0.22.2)\n",
      "Requirement already satisfied: numpy in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (1.26.4)\n",
      "Requirement already satisfied: oss2 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.18.4)\n",
      "Requirement already satisfied: pandas in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.2.1)\n",
      "Requirement already satisfied: Pillow>=6.2.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (10.3.0)\n",
      "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (15.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.25 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.31.0)\n",
      "Requirement already satisfied: scipy in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (69.2.0)\n",
      "Requirement already satisfied: simplejson>=3.3.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (3.19.2)\n",
      "Requirement already satisfied: sortedcontainers>=1.5.9 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (4.66.2)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.2.1)\n",
      "Requirement already satisfied: yapf in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (0.40.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets>=2.14.5->modelscope) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (3.9.3)\n",
      "Requirement already satisfied: packaging in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from huggingface-hub->modelscope) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from python-dateutil>=2.1->modelscope) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from requests>=2.25->modelscope) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from requests>=2.25->modelscope) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from requests>=2.25->modelscope) (2024.2.2)\n",
      "Requirement already satisfied: crcmod>=1.7 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from oss2->modelscope) (1.7)\n",
      "Requirement already satisfied: pycryptodome>=3.4.7 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from oss2->modelscope) (3.20.0)\n",
      "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from oss2->modelscope) (2.16.2)\n",
      "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from oss2->modelscope) (2.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from pandas->modelscope) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from pandas->modelscope) (2024.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from yapf->modelscope) (7.1.0)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from yapf->modelscope) (4.2.0)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from yapf->modelscope) (2.0.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (0.10.0)\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (42.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (1.9.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from importlib-metadata>=6.6.0->yapf->modelscope) (3.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install modelscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596c039b-3491-4bbd-b155-b4b482dd7f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 15:36:50,725 - modelscope - INFO - PyTorch version 2.2.2 Found.\n",
      "2024-04-07 15:36:50,727 - modelscope - INFO - Loading ast index from /home/liyongliang/.cache/modelscope/ast_indexer\n",
      "2024-04-07 15:36:50,934 - modelscope - INFO - Loading done! Current index file version is 1.13.3, with md5 08600c7f35b7b0c452f9e7e37116090a and a total number of 972 components indexed\n",
      "2024-04-07 15:36:52,252 - modelscope - INFO - Use user-specified model revision: v1.0.0\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download(\"ZhipuAI/chatglm3-6b\", revision = \"v1.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7a99923349056",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. 使用命令行开始微调,我们使用 lora 进行微调\n",
    "接着，我们仅需要将配置好的参数以命令行的形式传参给程序，就可以使用命令行进行高效微调，这里将 `/media/zr/Data/Code/ChatGLM3/venv/bin/python3` 换成你的 python3 的绝对路径以保证正常运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c87410a24d844f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T05:52:13.820670Z",
     "start_time": "2024-04-07T05:52:13.707968Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:04<00:00,  1.57it/s]\n",
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n",
      "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
      "Generating train split: 114599 examples [00:00, 613940.27 examples/s]\n",
      "Setting num_proc from 16 back to 1 for the validation split to disable multiprocessing as it only contains one shard.\n",
      "Generating validation split: 1070 examples [00:00, 424428.34 examples/s]\n",
      "Setting num_proc from 16 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n",
      "Generating test split: 1070 examples [00:00, 618253.93 examples/s]\n",
      "Map (num_proc=16): 100%|██████| 114599/114599 [00:01<00:00, 75376.06 examples/s]\n",
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 114599\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 2336.52 examples/s]\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 2641.68 examples/s]\n",
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "--> Sanity check\n",
      "           '[gMASK]': 64790 -> -100\n",
      "               'sop': 64792 -> -100\n",
      "          '<|user|>': 64795 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '\\n': 13 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '类型': 33467 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '版': 55090 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '宽松': 40833 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '风格': 32799 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '性感': 40589 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '图案': 37505 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '线条': 37216 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '阔': 56529 -> -100\n",
      "                 '腿': 56158 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "     '<|assistant|>': 64796 -> -100\n",
      "                  '': 30910 -> 30910\n",
      "                '\\n': 13 -> 13\n",
      "                  '': 30910 -> 30910\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '阔': 56529 -> 56529\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '这': 54551 -> 54551\n",
      "                '两年': 33808 -> 33808\n",
      "                '真的': 32041 -> 32041\n",
      "                 '吸': 55360 -> 55360\n",
      "                 '粉': 55486 -> 55486\n",
      "                '不少': 32138 -> 32138\n",
      "                 '，': 31123 -> 31123\n",
      "                '明星': 32943 -> 32943\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '达': 54880 -> 54880\n",
      "                '人的': 31664 -> 31664\n",
      "                '心头': 46565 -> 46565\n",
      "                 '爱': 54799 -> 54799\n",
      "                 '。': 31155 -> 31155\n",
      "                '毕竟': 33051 -> 33051\n",
      "                 '好': 54591 -> 54591\n",
      "                 '穿': 55432 -> 55432\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '，': 31123 -> 31123\n",
      "                 '谁': 55622 -> 55622\n",
      "                '都能': 32904 -> 32904\n",
      "                 '穿': 55432 -> 55432\n",
      "                 '出': 54557 -> 54557\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '长': 54625 -> 54625\n",
      "                 '2': 30943 -> 30943\n",
      "                 '米': 55055 -> 55055\n",
      "               '的效果': 35590 -> 35590\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '，': 31123 -> 31123\n",
      "               '当然是': 48466 -> 48466\n",
      "                 '遮': 57148 -> 57148\n",
      "                 '肉': 55343 -> 55343\n",
      "                 '小': 54603 -> 54603\n",
      "                '能手': 49355 -> 49355\n",
      "                 '啊': 55674 -> 55674\n",
      "                 '。': 31155 -> 31155\n",
      "                '上身': 51605 -> 51605\n",
      "                 '随': 55119 -> 55119\n",
      "                 '性': 54642 -> 54642\n",
      "                '自然': 31799 -> 31799\n",
      "                 '不': 54535 -> 54535\n",
      "                 '拘': 57036 -> 57036\n",
      "                 '束': 55625 -> 55625\n",
      "                 '，': 31123 -> 31123\n",
      "                '面料': 46839 -> 46839\n",
      "                 '亲': 55113 -> 55113\n",
      "                 '肤': 56089 -> 56089\n",
      "                '舒适': 33894 -> 33894\n",
      "                 '贴': 55778 -> 55778\n",
      "                '身体': 31902 -> 31902\n",
      "                 '验': 55017 -> 55017\n",
      "                 '感': 54706 -> 54706\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '哒': 59230 -> 59230\n",
      "                 '。': 31155 -> 31155\n",
      "                 '系': 54712 -> 54712\n",
      "                 '带': 54882 -> 54882\n",
      "                '部分': 31726 -> 31726\n",
      "                '增加': 31917 -> 31917\n",
      "                '设计': 31735 -> 31735\n",
      "                '看点': 45032 -> 45032\n",
      "                 '，': 31123 -> 31123\n",
      "                 '还': 54656 -> 54656\n",
      "                 '让': 54772 -> 54772\n",
      "                '单品': 46539 -> 46539\n",
      "               '的设计': 34481 -> 34481\n",
      "                 '感': 54706 -> 54706\n",
      "                '更强': 43084 -> 43084\n",
      "                 '。': 31155 -> 31155\n",
      "                '腿部': 46799 -> 46799\n",
      "                '线条': 37216 -> 37216\n",
      "                 '若': 55351 -> 55351\n",
      "                 '隐': 55733 -> 55733\n",
      "                 '若': 55351 -> 55351\n",
      "                 '现': 54600 -> 54600\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                '性感': 40589 -> 40589\n",
      "                 '撩': 58521 -> 58521\n",
      "                 '人': 54533 -> 54533\n",
      "                 '。': 31155 -> 31155\n",
      "                '颜色': 33692 -> 33692\n",
      "                 '敲': 57004 -> 57004\n",
      "                '温柔': 34678 -> 34678\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                 '与': 54619 -> 54619\n",
      "                '裤子': 44722 -> 44722\n",
      "                '本身': 32754 -> 32754\n",
      "                 '所': 54626 -> 54626\n",
      "                '呈现': 33169 -> 33169\n",
      "               '的风格': 48084 -> 48084\n",
      "                '有点': 33149 -> 33149\n",
      "                 '反': 54955 -> 54955\n",
      "                 '差': 55342 -> 55342\n",
      "                 '萌': 56842 -> 56842\n",
      "                 '。': 31155 -> 31155\n",
      "                  '': 2 -> 2\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "  Num examples = 114,599\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3,000\n",
      "  Number of trainable parameters = 1,949,696\n",
      "  0%|                                                  | 0/3000 [00:00<?, ?it/s]/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 4.8277, 'grad_norm': 2.211599826812744, 'learning_rate': 4.9833333333333336e-05, 'epoch': 0.0}\n",
      "{'loss': 4.5961, 'grad_norm': 3.178361654281616, 'learning_rate': 4.966666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 4.4758, 'grad_norm': 3.0038528442382812, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.0}\n",
      "{'loss': 4.117, 'grad_norm': 3.3005409240722656, 'learning_rate': 4.933333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 4.1152, 'grad_norm': 2.676926612854004, 'learning_rate': 4.9166666666666665e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8709, 'grad_norm': 2.9008007049560547, 'learning_rate': 4.9e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8445, 'grad_norm': 2.824059247970581, 'learning_rate': 4.883333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7488, 'grad_norm': 2.8761894702911377, 'learning_rate': 4.866666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6385, 'grad_norm': 3.1661746501922607, 'learning_rate': 4.85e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7229, 'grad_norm': 3.3487465381622314, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6721, 'grad_norm': 3.5285439491271973, 'learning_rate': 4.8166666666666674e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8512, 'grad_norm': 3.821624994277954, 'learning_rate': 4.8e-05, 'epoch': 0.0}\n",
      "{'loss': 3.615, 'grad_norm': 3.46592116355896, 'learning_rate': 4.7833333333333335e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7336, 'grad_norm': 4.391632080078125, 'learning_rate': 4.766666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6854, 'grad_norm': 3.6104562282562256, 'learning_rate': 4.75e-05, 'epoch': 0.01}\n",
      "{'loss': 3.7437, 'grad_norm': 3.9234724044799805, 'learning_rate': 4.7333333333333336e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5766, 'grad_norm': 4.061954021453857, 'learning_rate': 4.716666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5736, 'grad_norm': 4.273143768310547, 'learning_rate': 4.7e-05, 'epoch': 0.01}\n",
      "{'loss': 3.55, 'grad_norm': 4.841678142547607, 'learning_rate': 4.683333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5762, 'grad_norm': 4.510401725769043, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5496, 'grad_norm': 5.033932209014893, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6469, 'grad_norm': 4.041619300842285, 'learning_rate': 4.633333333333333e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6113, 'grad_norm': 4.752793312072754, 'learning_rate': 4.6166666666666666e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5104, 'grad_norm': 4.501155376434326, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4791, 'grad_norm': 5.383983612060547, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5998, 'grad_norm': 5.324463367462158, 'learning_rate': 4.566666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.548, 'grad_norm': 5.408894062042236, 'learning_rate': 4.55e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6156, 'grad_norm': 4.5405802726745605, 'learning_rate': 4.5333333333333335e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6301, 'grad_norm': 4.763795375823975, 'learning_rate': 4.516666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5396, 'grad_norm': 5.735761642456055, 'learning_rate': 4.5e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4662, 'grad_norm': 5.286923408508301, 'learning_rate': 4.483333333333333e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6088, 'grad_norm': 5.771271228790283, 'learning_rate': 4.466666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4189, 'grad_norm': 5.185227870941162, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4916, 'grad_norm': 5.259863376617432, 'learning_rate': 4.433333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5215, 'grad_norm': 5.518223285675049, 'learning_rate': 4.4166666666666665e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5752, 'grad_norm': 5.171401023864746, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3623, 'grad_norm': 4.867884635925293, 'learning_rate': 4.383333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5277, 'grad_norm': 5.136194229125977, 'learning_rate': 4.3666666666666666e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5215, 'grad_norm': 5.2248921394348145, 'learning_rate': 4.35e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4717, 'grad_norm': 5.609742164611816, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6916, 'grad_norm': 5.504353046417236, 'learning_rate': 4.316666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4963, 'grad_norm': 5.064664363861084, 'learning_rate': 4.3e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6246, 'grad_norm': 5.6376872062683105, 'learning_rate': 4.2833333333333335e-05, 'epoch': 0.02}\n",
      "{'loss': 3.418, 'grad_norm': 6.617984771728516, 'learning_rate': 4.266666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4176, 'grad_norm': 6.011755466461182, 'learning_rate': 4.25e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4273, 'grad_norm': 5.5912370681762695, 'learning_rate': 4.233333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5318, 'grad_norm': 5.712792873382568, 'learning_rate': 4.216666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.449, 'grad_norm': 7.196647644042969, 'learning_rate': 4.2e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4582, 'grad_norm': 5.735536575317383, 'learning_rate': 4.183333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5639, 'grad_norm': 5.892307758331299, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.02}\n",
      " 17%|██████▋                                 | 500/3000 [05:47<33:01,  1.26it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.81s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:08<00:03,  3.18s/it]\u001B[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  8.22s/it]\u001B[ABuilding prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.336 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "                                                                                \n",
      "\u001B[A{'eval_rouge-1': 31.312196, 'eval_rouge-2': 6.872972, 'eval_rouge-l': 23.841478, 'eval_bleu-4': 0.031110072980677875, 'eval_runtime': 44.5346, 'eval_samples_per_second': 1.123, 'eval_steps_per_second': 0.09, 'epoch': 0.02}\n",
      " 17%|██████▋                                 | 500/3000 [06:32<33:01,  1.26it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  8.22s/it]\u001B[A\n",
      "                                                                                \u001B[A/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3221, 'grad_norm': 5.754517555236816, 'learning_rate': 4.15e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5455, 'grad_norm': 6.57219934463501, 'learning_rate': 4.133333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5809, 'grad_norm': 5.9758124351501465, 'learning_rate': 4.116666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.485, 'grad_norm': 5.436893463134766, 'learning_rate': 4.1e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5248, 'grad_norm': 5.337273597717285, 'learning_rate': 4.0833333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.6498, 'grad_norm': 5.8406805992126465, 'learning_rate': 4.066666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4936, 'grad_norm': 5.823863506317139, 'learning_rate': 4.05e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3721, 'grad_norm': 5.649349212646484, 'learning_rate': 4.0333333333333336e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4285, 'grad_norm': 6.238030910491943, 'learning_rate': 4.016666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4928, 'grad_norm': 6.44059419631958, 'learning_rate': 4e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4418, 'grad_norm': 6.219210624694824, 'learning_rate': 3.983333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4586, 'grad_norm': 6.678772926330566, 'learning_rate': 3.966666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4486, 'grad_norm': 6.036410808563232, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4574, 'grad_norm': 6.152371883392334, 'learning_rate': 3.933333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5352, 'grad_norm': 5.898171901702881, 'learning_rate': 3.9166666666666665e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4816, 'grad_norm': 6.339001178741455, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5434, 'grad_norm': 6.206179618835449, 'learning_rate': 3.883333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.307, 'grad_norm': 7.09702730178833, 'learning_rate': 3.866666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4012, 'grad_norm': 6.602102279663086, 'learning_rate': 3.85e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3576, 'grad_norm': 6.2985148429870605, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4984, 'grad_norm': 7.148566246032715, 'learning_rate': 3.816666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5291, 'grad_norm': 6.8081793785095215, 'learning_rate': 3.8e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2471, 'grad_norm': 6.858859062194824, 'learning_rate': 3.7833333333333336e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5723, 'grad_norm': 5.8460373878479, 'learning_rate': 3.766666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.401, 'grad_norm': 6.391196250915527, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4756, 'grad_norm': 6.200255393981934, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.6221, 'grad_norm': 6.424304008483887, 'learning_rate': 3.7166666666666664e-05, 'epoch': 0.03}\n",
      "{'loss': 3.473, 'grad_norm': 6.323575496673584, 'learning_rate': 3.7e-05, 'epoch': 0.03}\n",
      "{'loss': 3.326, 'grad_norm': 6.533908843994141, 'learning_rate': 3.683333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5504, 'grad_norm': 6.899112701416016, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2896, 'grad_norm': 6.578380107879639, 'learning_rate': 3.65e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3611, 'grad_norm': 6.518515586853027, 'learning_rate': 3.633333333333333e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4629, 'grad_norm': 7.1850996017456055, 'learning_rate': 3.6166666666666674e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4074, 'grad_norm': 6.299108028411865, 'learning_rate': 3.6e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5084, 'grad_norm': 6.210760593414307, 'learning_rate': 3.5833333333333335e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5342, 'grad_norm': 6.175666809082031, 'learning_rate': 3.566666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2971, 'grad_norm': 7.241196155548096, 'learning_rate': 3.55e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4951, 'grad_norm': 6.760175704956055, 'learning_rate': 3.5333333333333336e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4529, 'grad_norm': 7.483913421630859, 'learning_rate': 3.516666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2689, 'grad_norm': 7.76351261138916, 'learning_rate': 3.5e-05, 'epoch': 0.03}\n",
      "{'loss': 3.46, 'grad_norm': 7.83445930480957, 'learning_rate': 3.483333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4205, 'grad_norm': 6.944183826446533, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4619, 'grad_norm': 7.467222690582275, 'learning_rate': 3.45e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5707, 'grad_norm': 7.253203868865967, 'learning_rate': 3.433333333333333e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3619, 'grad_norm': 6.532739162445068, 'learning_rate': 3.4166666666666666e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4361, 'grad_norm': 7.916663646697998, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5404, 'grad_norm': 5.989049911499023, 'learning_rate': 3.3833333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3232, 'grad_norm': 7.032818794250488, 'learning_rate': 3.366666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4615, 'grad_norm': 7.314331531524658, 'learning_rate': 3.35e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3965, 'grad_norm': 7.895094871520996, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.03}\n",
      " 33%|█████████████                          | 1000/3000 [12:15<23:16,  1.43it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.61s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:06<00:02,  2.31s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.019874, 'eval_rouge-2': 6.710062000000001, 'eval_rouge-l': 25.805936000000003, 'eval_bleu-4': 0.03586304411311721, 'eval_runtime': 12.655, 'eval_samples_per_second': 3.951, 'eval_steps_per_second': 0.316, 'epoch': 0.03}\n",
      " 33%|█████████████                          | 1000/3000 [12:27<23:16,  1.43it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:09<00:00,  2.40s/it]\u001B[A\n",
      "                                                                                \u001B[A/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.4506, 'grad_norm': 6.957945346832275, 'learning_rate': 3.316666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4588, 'grad_norm': 7.5320353507995605, 'learning_rate': 3.3e-05, 'epoch': 0.04}\n",
      "{'loss': 3.6469, 'grad_norm': 8.310067176818848, 'learning_rate': 3.283333333333333e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4018, 'grad_norm': 6.5941877365112305, 'learning_rate': 3.266666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3893, 'grad_norm': 8.613672256469727, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3576, 'grad_norm': 7.719951629638672, 'learning_rate': 3.233333333333333e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3906, 'grad_norm': 7.244112014770508, 'learning_rate': 3.2166666666666665e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4611, 'grad_norm': 7.291880130767822, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.04}\n",
      "{'loss': 3.5281, 'grad_norm': 7.145831108093262, 'learning_rate': 3.183333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.466, 'grad_norm': 6.685605525970459, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3416, 'grad_norm': 6.912548542022705, 'learning_rate': 3.15e-05, 'epoch': 0.04}\n",
      "{'loss': 3.526, 'grad_norm': 7.89657735824585, 'learning_rate': 3.1333333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4352, 'grad_norm': 7.466870307922363, 'learning_rate': 3.116666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3588, 'grad_norm': 8.044967651367188, 'learning_rate': 3.1e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3213, 'grad_norm': 7.616206169128418, 'learning_rate': 3.0833333333333335e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3627, 'grad_norm': 7.337640762329102, 'learning_rate': 3.066666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4502, 'grad_norm': 6.809033393859863, 'learning_rate': 3.05e-05, 'epoch': 0.04}\n",
      "{'loss': 3.474, 'grad_norm': 6.503211975097656, 'learning_rate': 3.0333333333333337e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3584, 'grad_norm': 6.680871963500977, 'learning_rate': 3.016666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4088, 'grad_norm': 6.455650806427002, 'learning_rate': 3e-05, 'epoch': 0.04}\n",
      "{'loss': 3.2439, 'grad_norm': 6.763891696929932, 'learning_rate': 2.9833333333333335e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3436, 'grad_norm': 7.445559024810791, 'learning_rate': 2.9666666666666672e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3789, 'grad_norm': 7.464072227478027, 'learning_rate': 2.95e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3766, 'grad_norm': 7.65313196182251, 'learning_rate': 2.9333333333333336e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4471, 'grad_norm': 6.749969005584717, 'learning_rate': 2.916666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.2803, 'grad_norm': 7.637670993804932, 'learning_rate': 2.9e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4609, 'grad_norm': 7.2154154777526855, 'learning_rate': 2.8833333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.335, 'grad_norm': 7.300796031951904, 'learning_rate': 2.8666666666666668e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3885, 'grad_norm': 6.9707560539245605, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4791, 'grad_norm': 7.4061102867126465, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.05}\n",
      "{'loss': 3.46, 'grad_norm': 6.978759288787842, 'learning_rate': 2.816666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4549, 'grad_norm': 6.8180694580078125, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4045, 'grad_norm': 10.345161437988281, 'learning_rate': 2.7833333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3059, 'grad_norm': 7.495015621185303, 'learning_rate': 2.7666666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3477, 'grad_norm': 7.670158863067627, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3021, 'grad_norm': 8.024333953857422, 'learning_rate': 2.733333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.5201, 'grad_norm': 7.356316089630127, 'learning_rate': 2.716666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3859, 'grad_norm': 7.234160423278809, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3586, 'grad_norm': 7.275804042816162, 'learning_rate': 2.6833333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4154, 'grad_norm': 6.7652387619018555, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3465, 'grad_norm': 7.459606170654297, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2687, 'grad_norm': 7.862022876739502, 'learning_rate': 2.633333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3787, 'grad_norm': 7.730146884918213, 'learning_rate': 2.6166666666666668e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3586, 'grad_norm': 7.295705795288086, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2689, 'grad_norm': 7.061826229095459, 'learning_rate': 2.5833333333333336e-05, 'epoch': 0.05}\n",
      "{'loss': 3.392, 'grad_norm': 7.3267011642456055, 'learning_rate': 2.5666666666666666e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4391, 'grad_norm': 9.118309020996094, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3004, 'grad_norm': 6.78839635848999, 'learning_rate': 2.5333333333333337e-05, 'epoch': 0.05}\n",
      "{'loss': 3.442, 'grad_norm': 7.507795810699463, 'learning_rate': 2.5166666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4594, 'grad_norm': 7.0092926025390625, 'learning_rate': 2.5e-05, 'epoch': 0.05}\n",
      " 50%|███████████████████▌                   | 1500/3000 [18:02<15:05,  1.66it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.94s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:23<00:09,  9.29s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.922556000000004, 'eval_rouge-2': 6.85235, 'eval_rouge-l': 25.046247999999995, 'eval_bleu-4': 0.03367503532806086, 'eval_runtime': 29.0892, 'eval_samples_per_second': 1.719, 'eval_steps_per_second': 0.138, 'epoch': 0.05}\n",
      " 50%|███████████████████▌                   | 1500/3000 [18:31<15:05,  1.66it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  6.61s/it]\u001B[A\n",
      "                                                                                \u001B[A/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.342, 'grad_norm': 6.932469844818115, 'learning_rate': 2.4833333333333335e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3881, 'grad_norm': 8.364788055419922, 'learning_rate': 2.466666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4395, 'grad_norm': 8.24215030670166, 'learning_rate': 2.45e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4082, 'grad_norm': 7.27025842666626, 'learning_rate': 2.4333333333333336e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4934, 'grad_norm': 7.423466205596924, 'learning_rate': 2.4166666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4092, 'grad_norm': 8.4327392578125, 'learning_rate': 2.4e-05, 'epoch': 0.05}\n",
      "{'loss': 3.466, 'grad_norm': 8.045676231384277, 'learning_rate': 2.3833333333333334e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4383, 'grad_norm': 7.641425609588623, 'learning_rate': 2.3666666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5166, 'grad_norm': 9.251279830932617, 'learning_rate': 2.35e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3936, 'grad_norm': 6.975968360900879, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3717, 'grad_norm': 8.025012969970703, 'learning_rate': 2.3166666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3703, 'grad_norm': 8.4968900680542, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4693, 'grad_norm': 7.2917985916137695, 'learning_rate': 2.2833333333333334e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3184, 'grad_norm': 8.028616905212402, 'learning_rate': 2.2666666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3725, 'grad_norm': 7.567887783050537, 'learning_rate': 2.25e-05, 'epoch': 0.06}\n",
      "{'loss': 3.307, 'grad_norm': 7.046629905700684, 'learning_rate': 2.2333333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4787, 'grad_norm': 8.677409172058105, 'learning_rate': 2.216666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3744, 'grad_norm': 7.319756507873535, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3797, 'grad_norm': 7.441025733947754, 'learning_rate': 2.1833333333333333e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5195, 'grad_norm': 7.16675329208374, 'learning_rate': 2.1666666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4615, 'grad_norm': 7.348052024841309, 'learning_rate': 2.15e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5029, 'grad_norm': 7.553962707519531, 'learning_rate': 2.1333333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4039, 'grad_norm': 7.565986633300781, 'learning_rate': 2.116666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.402, 'grad_norm': 7.735357761383057, 'learning_rate': 2.1e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4645, 'grad_norm': 7.492410659790039, 'learning_rate': 2.0833333333333336e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4469, 'grad_norm': 7.910346984863281, 'learning_rate': 2.0666666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.367, 'grad_norm': 8.549391746520996, 'learning_rate': 2.05e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3547, 'grad_norm': 8.26020622253418, 'learning_rate': 2.0333333333333334e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3955, 'grad_norm': 8.26387882232666, 'learning_rate': 2.0166666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3406, 'grad_norm': 7.879659652709961, 'learning_rate': 2e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3795, 'grad_norm': 8.827082633972168, 'learning_rate': 1.9833333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3445, 'grad_norm': 7.776710033416748, 'learning_rate': 1.9666666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5875, 'grad_norm': 7.893863677978516, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3514, 'grad_norm': 8.519519805908203, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4937, 'grad_norm': 9.129216194152832, 'learning_rate': 1.9166666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3822, 'grad_norm': 7.396079063415527, 'learning_rate': 1.9e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3172, 'grad_norm': 8.14787769317627, 'learning_rate': 1.8833333333333335e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3082, 'grad_norm': 7.315348148345947, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4006, 'grad_norm': 7.307248592376709, 'learning_rate': 1.85e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3682, 'grad_norm': 7.882397174835205, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3896, 'grad_norm': 8.077428817749023, 'learning_rate': 1.8166666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4826, 'grad_norm': 7.496025562286377, 'learning_rate': 1.8e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2842, 'grad_norm': 7.77559757232666, 'learning_rate': 1.7833333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5023, 'grad_norm': 7.710636138916016, 'learning_rate': 1.7666666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3631, 'grad_norm': 7.051712989807129, 'learning_rate': 1.75e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2885, 'grad_norm': 8.812463760375977, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3736, 'grad_norm': 7.738472938537598, 'learning_rate': 1.7166666666666666e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2432, 'grad_norm': 7.56613302230835, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 3.416, 'grad_norm': 7.1319732666015625, 'learning_rate': 1.6833333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4678, 'grad_norm': 7.9318132400512695, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.07}\n",
      " 67%|██████████████████████████             | 2000/3000 [24:07<10:56,  1.52it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:04<00:04,  2.18s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:22<00:08,  8.71s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 30.6729, 'eval_rouge-2': 6.53428, 'eval_rouge-l': 24.032650000000004, 'eval_bleu-4': 0.03237400599162966, 'eval_runtime': 56.4354, 'eval_samples_per_second': 0.886, 'eval_steps_per_second': 0.071, 'epoch': 0.07}\n",
      " 67%|██████████████████████████             | 2000/3000 [25:04<10:56,  1.52it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:36<00:00, 10.81s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output/checkpoint-2000\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /home/liyongliang/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/ - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3879, 'grad_norm': 8.769264221191406, 'learning_rate': 1.65e-05, 'epoch': 0.07}\n",
      "{'loss': 3.501, 'grad_norm': 7.419240474700928, 'learning_rate': 1.6333333333333335e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5572, 'grad_norm': 9.05588436126709, 'learning_rate': 1.6166666666666665e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4934, 'grad_norm': 8.41662311553955, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3687, 'grad_norm': 8.143022537231445, 'learning_rate': 1.5833333333333333e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3287, 'grad_norm': 7.855011463165283, 'learning_rate': 1.5666666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4428, 'grad_norm': 8.233463287353516, 'learning_rate': 1.55e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4205, 'grad_norm': 8.298272132873535, 'learning_rate': 1.5333333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.44, 'grad_norm': 7.463931083679199, 'learning_rate': 1.5166666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.358, 'grad_norm': 7.682419300079346, 'learning_rate': 1.5e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2973, 'grad_norm': 7.625631809234619, 'learning_rate': 1.4833333333333336e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5893, 'grad_norm': 8.055710792541504, 'learning_rate': 1.4666666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2533, 'grad_norm': 7.791656970977783, 'learning_rate': 1.45e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3613, 'grad_norm': 8.122137069702148, 'learning_rate': 1.4333333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4002, 'grad_norm': 7.40869140625, 'learning_rate': 1.4166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.523, 'grad_norm': 8.064817428588867, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3982, 'grad_norm': 6.785824775695801, 'learning_rate': 1.3833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4158, 'grad_norm': 8.041714668273926, 'learning_rate': 1.3666666666666666e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3543, 'grad_norm': 7.873022079467773, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4361, 'grad_norm': 7.685222148895264, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4488, 'grad_norm': 6.833673000335693, 'learning_rate': 1.3166666666666665e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4209, 'grad_norm': 7.816983699798584, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.417, 'grad_norm': 7.965836048126221, 'learning_rate': 1.2833333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3723, 'grad_norm': 8.308736801147461, 'learning_rate': 1.2666666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2354, 'grad_norm': 8.546222686767578, 'learning_rate': 1.25e-05, 'epoch': 0.08}\n",
      "{'loss': 3.366, 'grad_norm': 7.936026573181152, 'learning_rate': 1.2333333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4303, 'grad_norm': 8.631184577941895, 'learning_rate': 1.2166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4676, 'grad_norm': 7.739234447479248, 'learning_rate': 1.2e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2926, 'grad_norm': 8.225676536560059, 'learning_rate': 1.1833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3596, 'grad_norm': 8.534008979797363, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3217, 'grad_norm': 8.48660659790039, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3299, 'grad_norm': 8.45600414276123, 'learning_rate': 1.1333333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3711, 'grad_norm': 8.89610767364502, 'learning_rate': 1.1166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3635, 'grad_norm': 7.796140670776367, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2721, 'grad_norm': 8.526595115661621, 'learning_rate': 1.0833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3746, 'grad_norm': 8.249107360839844, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3543, 'grad_norm': 7.968107223510742, 'learning_rate': 1.05e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4941, 'grad_norm': 8.530204772949219, 'learning_rate': 1.0333333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2396, 'grad_norm': 8.57210922241211, 'learning_rate': 1.0166666666666667e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4621, 'grad_norm': 7.876626014709473, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4547, 'grad_norm': 8.31406307220459, 'learning_rate': 9.833333333333333e-06, 'epoch': 0.08}\n",
      "{'loss': 3.282, 'grad_norm': 8.064860343933105, 'learning_rate': 9.666666666666667e-06, 'epoch': 0.08}\n",
      "{'loss': 3.375, 'grad_norm': 7.400005340576172, 'learning_rate': 9.5e-06, 'epoch': 0.08}\n",
      "{'loss': 3.383, 'grad_norm': 7.968774318695068, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2789, 'grad_norm': 7.77604866027832, 'learning_rate': 9.166666666666666e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3127, 'grad_norm': 7.856767654418945, 'learning_rate': 9e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2611, 'grad_norm': 8.787678718566895, 'learning_rate': 8.833333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4361, 'grad_norm': 7.498402118682861, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4727, 'grad_norm': 7.966836929321289, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3959, 'grad_norm': 9.483956336975098, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.09}\n",
      " 83%|████████████████████████████████▌      | 2500/3000 [31:43<07:06,  1.17it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.99s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:07<00:02,  2.48s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.703215999999998, 'eval_rouge-2': 6.577932, 'eval_rouge-l': 24.864494, 'eval_bleu-4': 0.0322564250260483, 'eval_runtime': 29.2395, 'eval_samples_per_second': 1.71, 'eval_steps_per_second': 0.137, 'epoch': 0.09}\n",
      " 83%|████████████████████████████████▌      | 2500/3000 [32:12<07:06,  1.17it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  8.41s/it]\u001B[A\n",
      "                                                                                \u001B[A/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3043, 'grad_norm': 8.53369426727295, 'learning_rate': 8.166666666666668e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3412, 'grad_norm': 10.167778015136719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2482, 'grad_norm': 7.976165771484375, 'learning_rate': 7.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4002, 'grad_norm': 8.225594520568848, 'learning_rate': 7.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3945, 'grad_norm': 7.961778163909912, 'learning_rate': 7.5e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4059, 'grad_norm': 8.482867240905762, 'learning_rate': 7.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4729, 'grad_norm': 8.058754920959473, 'learning_rate': 7.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4834, 'grad_norm': 8.517905235290527, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3768, 'grad_norm': 8.428369522094727, 'learning_rate': 6.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4795, 'grad_norm': 8.748512268066406, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3586, 'grad_norm': 8.004413604736328, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4238, 'grad_norm': 7.767560005187988, 'learning_rate': 6.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.5258, 'grad_norm': 7.640416622161865, 'learning_rate': 6.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4447, 'grad_norm': 8.53693675994873, 'learning_rate': 6e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4133, 'grad_norm': 8.22100830078125, 'learning_rate': 5.833333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3539, 'grad_norm': 8.038525581359863, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.41, 'grad_norm': 8.651084899902344, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2709, 'grad_norm': 7.591857433319092, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.477, 'grad_norm': 8.727055549621582, 'learning_rate': 5.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4537, 'grad_norm': 8.883668899536133, 'learning_rate': 5e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4309, 'grad_norm': 8.550275802612305, 'learning_rate': 4.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2537, 'grad_norm': 7.589319229125977, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3801, 'grad_norm': 7.9352126121521, 'learning_rate': 4.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3855, 'grad_norm': 8.021224975585938, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4578, 'grad_norm': 8.941168785095215, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4018, 'grad_norm': 8.094531059265137, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3486, 'grad_norm': 8.31187915802002, 'learning_rate': 3.833333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2617, 'grad_norm': 8.604520797729492, 'learning_rate': 3.666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2826, 'grad_norm': 8.211206436157227, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2455, 'grad_norm': 7.699353218078613, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4473, 'grad_norm': 7.906303405761719, 'learning_rate': 3.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3723, 'grad_norm': 8.142539978027344, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3912, 'grad_norm': 8.103194236755371, 'learning_rate': 2.8333333333333335e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4406, 'grad_norm': 9.12052059173584, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4045, 'grad_norm': 8.615226745605469, 'learning_rate': 2.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3381, 'grad_norm': 8.439209938049316, 'learning_rate': 2.3333333333333336e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3773, 'grad_norm': 8.820865631103516, 'learning_rate': 2.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.5092, 'grad_norm': 9.148855209350586, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3041, 'grad_norm': 8.294098854064941, 'learning_rate': 1.8333333333333335e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3295, 'grad_norm': 9.05016040802002, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3062, 'grad_norm': 8.158592224121094, 'learning_rate': 1.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2494, 'grad_norm': 7.318261623382568, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3633, 'grad_norm': 8.954392433166504, 'learning_rate': 1.1666666666666668e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2563, 'grad_norm': 8.619033813476562, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3791, 'grad_norm': 8.18076229095459, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.1}\n",
      "{'loss': 3.2098, 'grad_norm': 8.971842765808105, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.1}\n",
      "{'loss': 3.4469, 'grad_norm': 9.037346839904785, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.1}\n",
      "{'loss': 3.4312, 'grad_norm': 8.976421356201172, 'learning_rate': 3.3333333333333335e-07, 'epoch': 0.1}\n",
      "{'loss': 3.477, 'grad_norm': 8.08509635925293, 'learning_rate': 1.6666666666666668e-07, 'epoch': 0.1}\n",
      "{'loss': 3.3684, 'grad_norm': 7.738158226013184, 'learning_rate': 0.0, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [39:37<00:00,  1.45it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:19<00:19,  9.90s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:39<00:13, 13.97s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.700896000000007, 'eval_rouge-2': 7.01834, 'eval_rouge-l': 23.556576, 'eval_bleu-4': 0.030983820866131752, 'eval_runtime': 76.2097, 'eval_samples_per_second': 0.656, 'eval_steps_per_second': 0.052, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [40:53<00:00,  1.45it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:56<00:00, 14.97s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 2453.9911, 'train_samples_per_second': 4.89, 'train_steps_per_second': 1.222, 'train_loss': 3.447244140625, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [40:53<00:00,  1.22it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1070\n",
      "  Batch size = 16\n",
      "100%|███████████████████████████████████████████| 67/67 [15:45<00:00, 14.12s/it]\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 finetune_hf.py  data/AdvertiseGen_fix  ~/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/  configs/lora.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9418f6c5c264601",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3. 使用微调的数据集进行推理\n",
    "在完成微调任务之后，我们可以查看到 `output` 文件夹下多了很多个`checkpoint-*`的文件夹，这些文件夹代表了训练的轮数。\n",
    "我们选择最后一轮的微调权重，并使用inference进行导入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f22b735175e1c0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T05:51:18.377240Z",
     "start_time": "2024-04-07T05:51:18.269219Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-2000\n"
     ]
    }
   ],
   "source": [
    "!ls output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5060015c24e97ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T05:51:19.277953Z",
     "start_time": "2024-04-07T05:51:19.165655Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:09<00:00,  1.35s/it]\n",
      "这款连衣裙采用网纱拼接设计，极具设计感，穿在身上不仅显得性感的气质，而且也极具时尚感。不规则的压褶设计，彰显出女性的优雅气质，而袖子上的木耳边设计，更是增加整体的设计感，而拉链的套头设计，穿脱方便，十分方便。\n"
     ]
    }
   ],
   "source": "!CUDA_VISIBLE_DEVICES=0  python3 inference_hf.py output/checkpoint-2000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
  },
  {
   "cell_type": "markdown",
   "id": "18cd83087f096094",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. 总结\n",
    "到此位置，我们就完成了使用单张 GPU Lora 来微调 ChatGLM3-6B 模型，使其能生产出更好的广告。\n",
    "在本章节中，你将会学会：\n",
    "+ 如何使用模型进行 Lora 微调\n",
    "+ 微调数据集的准备和对齐\n",
    "+ 使用微调的模型进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43859eff3085c954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
