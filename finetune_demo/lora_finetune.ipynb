{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b89f64d8f8053d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
    "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
    "\n",
    "## 硬件需求\n",
    "显存：24GB\n",
    "显卡架构：安培架构（推荐）\n",
    "内存：16GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42937756-6062-4677-ac18-9501154f222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr  7 19:08:49 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.65                 Driver Version: 551.86         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080        On  |   00000000:01:00.0  On |                  N/A |\n",
      "| 30%   31C    P8             13W /  320W |    1181MiB /  16376MiB |     12%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        28      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd9a514ed09ea6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. 准备数据集\n",
    "我们使用 AdvertiseGen 数据集来进行微调。从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 AdvertiseGen 数据集，将解压后的 AdvertiseGen 目录放到本目录的 `/data/` 下, 例如。\n",
    "> /media/zr/Data/Code/ChatGLM3/finetune_demo/data/AdvertiseGen\n",
    "\n",
    "接着，运行本代码来切割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T05:52:10.089622Z",
     "start_time": "2024-04-07T05:52:09.268873Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def _mkdir(dir_name: Union[str, Path]):\n",
    "    dir_name = _resolve_path(dir_name)\n",
    "    if not dir_name.is_dir():\n",
    "        dir_name.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
    "    def _convert(in_file: Path, out_file: Path):\n",
    "        _mkdir(out_file.parent)\n",
    "        with open(in_file, encoding='utf-8') as fin:\n",
    "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
    "                for line in fin:\n",
    "                    dct = json.loads(line)\n",
    "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
    "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
    "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    data_dir = _resolve_path(data_dir)\n",
    "    save_dir = _resolve_path(save_dir)\n",
    "\n",
    "    train_file = data_dir / 'train.json'\n",
    "    if train_file.is_file():\n",
    "        out_file = save_dir / train_file.relative_to(data_dir)\n",
    "        _convert(train_file, out_file)\n",
    "\n",
    "    dev_file = data_dir / 'dev.json'\n",
    "    if dev_file.is_file():\n",
    "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
    "        _convert(dev_file, out_file)\n",
    "\n",
    "\n",
    "convert_adgen('data/AdvertiseGen', 'data/AdvertiseGen_fix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a4325c-4c88-4fec-8131-fd432c79434e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modelscope in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (1.13.3)\n",
      "Requirement already satisfied: addict in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.4.0)\n",
      "Requirement already satisfied: attrs in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (23.2.0)\n",
      "Requirement already satisfied: datasets>=2.14.5 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.18.0)\n",
      "Requirement already satisfied: einops in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (0.7.0)\n",
      "Requirement already satisfied: filelock>=3.3.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (3.13.3)\n",
      "Requirement already satisfied: gast>=0.2.2 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (0.5.4)\n",
      "Requirement already satisfied: huggingface-hub in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (0.22.2)\n",
      "Requirement already satisfied: numpy in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (1.26.4)\n",
      "Requirement already satisfied: oss2 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.18.4)\n",
      "Requirement already satisfied: pandas in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.2.1)\n",
      "Requirement already satisfied: Pillow>=6.2.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (10.3.0)\n",
      "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (15.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.25 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.31.0)\n",
      "Requirement already satisfied: scipy in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (69.2.0)\n",
      "Requirement already satisfied: simplejson>=3.3.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (3.19.2)\n",
      "Requirement already satisfied: sortedcontainers>=1.5.9 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (4.66.2)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (2.2.1)\n",
      "Requirement already satisfied: yapf in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from modelscope) (0.40.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets>=2.14.5->modelscope) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (3.9.3)\n",
      "Requirement already satisfied: packaging in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from datasets>=2.14.5->modelscope) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from huggingface-hub->modelscope) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from python-dateutil>=2.1->modelscope) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from requests>=2.25->modelscope) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from requests>=2.25->modelscope) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from requests>=2.25->modelscope) (2024.2.2)\n",
      "Requirement already satisfied: crcmod>=1.7 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from oss2->modelscope) (1.7)\n",
      "Requirement already satisfied: pycryptodome>=3.4.7 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from oss2->modelscope) (3.20.0)\n",
      "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from oss2->modelscope) (2.16.2)\n",
      "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from oss2->modelscope) (2.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from pandas->modelscope) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from pandas->modelscope) (2024.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from yapf->modelscope) (7.1.0)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from yapf->modelscope) (4.2.0)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from yapf->modelscope) (2.0.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (0.10.0)\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (42.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from aiohttp->datasets>=2.14.5->modelscope) (1.9.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from importlib-metadata>=6.6.0->yapf->modelscope) (3.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install modelscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596c039b-3491-4bbd-b155-b4b482dd7f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 19:08:54,828 - modelscope - INFO - PyTorch version 2.2.2 Found.\n",
      "2024-04-07 19:08:54,829 - modelscope - INFO - Loading ast index from /home/liyongliang/.cache/modelscope/ast_indexer\n",
      "2024-04-07 19:08:54,881 - modelscope - INFO - Loading done! Current index file version is 1.13.3, with md5 08600c7f35b7b0c452f9e7e37116090a and a total number of 972 components indexed\n",
      "2024-04-07 19:08:56,224 - modelscope - INFO - Use user-specified model revision: v1.0.0\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download(\"ZhipuAI/chatglm3-6b\", revision = \"v1.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7a99923349056",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. 使用命令行开始微调,我们使用 lora 进行微调\n",
    "接着，我们仅需要将配置好的参数以命令行的形式传参给程序，就可以使用命令行进行高效微调，这里将 `/media/zr/Data/Code/ChatGLM3/venv/bin/python3` 换成你的 python3 的绝对路径以保证正常运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c87410a24d844f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T05:52:13.820670Z",
     "start_time": "2024-04-07T05:52:13.707968Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:03<00:00,  1.89it/s]\n",
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n",
      "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
      "Generating train split: 114599 examples [00:00, 998635.10 examples/s] \n",
      "Setting num_proc from 16 back to 1 for the validation split to disable multiprocessing as it only contains one shard.\n",
      "Generating validation split: 1070 examples [00:00, 385956.77 examples/s]\n",
      "Setting num_proc from 16 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n",
      "Generating test split: 1070 examples [00:00, 642322.21 examples/s]\n",
      "Map (num_proc=16): 100%|██████| 114599/114599 [00:01<00:00, 76382.66 examples/s]\n",
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 114599\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 2403.42 examples/s]\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 2772.12 examples/s]\n",
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "--> Sanity check\n",
      "           '[gMASK]': 64790 -> -100\n",
      "               'sop': 64792 -> -100\n",
      "          '<|user|>': 64795 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '\\n': 13 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '类型': 33467 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '版': 55090 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '宽松': 40833 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '风格': 32799 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '性感': 40589 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '图案': 37505 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '线条': 37216 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '阔': 56529 -> -100\n",
      "                 '腿': 56158 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "     '<|assistant|>': 64796 -> -100\n",
      "                  '': 30910 -> 30910\n",
      "                '\\n': 13 -> 13\n",
      "                  '': 30910 -> 30910\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '阔': 56529 -> 56529\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '这': 54551 -> 54551\n",
      "                '两年': 33808 -> 33808\n",
      "                '真的': 32041 -> 32041\n",
      "                 '吸': 55360 -> 55360\n",
      "                 '粉': 55486 -> 55486\n",
      "                '不少': 32138 -> 32138\n",
      "                 '，': 31123 -> 31123\n",
      "                '明星': 32943 -> 32943\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '达': 54880 -> 54880\n",
      "                '人的': 31664 -> 31664\n",
      "                '心头': 46565 -> 46565\n",
      "                 '爱': 54799 -> 54799\n",
      "                 '。': 31155 -> 31155\n",
      "                '毕竟': 33051 -> 33051\n",
      "                 '好': 54591 -> 54591\n",
      "                 '穿': 55432 -> 55432\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '，': 31123 -> 31123\n",
      "                 '谁': 55622 -> 55622\n",
      "                '都能': 32904 -> 32904\n",
      "                 '穿': 55432 -> 55432\n",
      "                 '出': 54557 -> 54557\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '长': 54625 -> 54625\n",
      "                 '2': 30943 -> 30943\n",
      "                 '米': 55055 -> 55055\n",
      "               '的效果': 35590 -> 35590\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '，': 31123 -> 31123\n",
      "               '当然是': 48466 -> 48466\n",
      "                 '遮': 57148 -> 57148\n",
      "                 '肉': 55343 -> 55343\n",
      "                 '小': 54603 -> 54603\n",
      "                '能手': 49355 -> 49355\n",
      "                 '啊': 55674 -> 55674\n",
      "                 '。': 31155 -> 31155\n",
      "                '上身': 51605 -> 51605\n",
      "                 '随': 55119 -> 55119\n",
      "                 '性': 54642 -> 54642\n",
      "                '自然': 31799 -> 31799\n",
      "                 '不': 54535 -> 54535\n",
      "                 '拘': 57036 -> 57036\n",
      "                 '束': 55625 -> 55625\n",
      "                 '，': 31123 -> 31123\n",
      "                '面料': 46839 -> 46839\n",
      "                 '亲': 55113 -> 55113\n",
      "                 '肤': 56089 -> 56089\n",
      "                '舒适': 33894 -> 33894\n",
      "                 '贴': 55778 -> 55778\n",
      "                '身体': 31902 -> 31902\n",
      "                 '验': 55017 -> 55017\n",
      "                 '感': 54706 -> 54706\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '哒': 59230 -> 59230\n",
      "                 '。': 31155 -> 31155\n",
      "                 '系': 54712 -> 54712\n",
      "                 '带': 54882 -> 54882\n",
      "                '部分': 31726 -> 31726\n",
      "                '增加': 31917 -> 31917\n",
      "                '设计': 31735 -> 31735\n",
      "                '看点': 45032 -> 45032\n",
      "                 '，': 31123 -> 31123\n",
      "                 '还': 54656 -> 54656\n",
      "                 '让': 54772 -> 54772\n",
      "                '单品': 46539 -> 46539\n",
      "               '的设计': 34481 -> 34481\n",
      "                 '感': 54706 -> 54706\n",
      "                '更强': 43084 -> 43084\n",
      "                 '。': 31155 -> 31155\n",
      "                '腿部': 46799 -> 46799\n",
      "                '线条': 37216 -> 37216\n",
      "                 '若': 55351 -> 55351\n",
      "                 '隐': 55733 -> 55733\n",
      "                 '若': 55351 -> 55351\n",
      "                 '现': 54600 -> 54600\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                '性感': 40589 -> 40589\n",
      "                 '撩': 58521 -> 58521\n",
      "                 '人': 54533 -> 54533\n",
      "                 '。': 31155 -> 31155\n",
      "                '颜色': 33692 -> 33692\n",
      "                 '敲': 57004 -> 57004\n",
      "                '温柔': 34678 -> 34678\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                 '与': 54619 -> 54619\n",
      "                '裤子': 44722 -> 44722\n",
      "                '本身': 32754 -> 32754\n",
      "                 '所': 54626 -> 54626\n",
      "                '呈现': 33169 -> 33169\n",
      "               '的风格': 48084 -> 48084\n",
      "                '有点': 33149 -> 33149\n",
      "                 '反': 54955 -> 54955\n",
      "                 '差': 55342 -> 55342\n",
      "                 '萌': 56842 -> 56842\n",
      "                 '。': 31155 -> 31155\n",
      "                  '': 2 -> 2\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "  Num examples = 114,599\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3,000\n",
      "  Number of trainable parameters = 1,949,696\n",
      "  0%|                                                  | 0/3000 [00:00<?, ?it/s]/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 4.8301, 'grad_norm': 2.1775810718536377, 'learning_rate': 4.9833333333333336e-05, 'epoch': 0.0}\n",
      "{'loss': 4.6016, 'grad_norm': 3.120826244354248, 'learning_rate': 4.966666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 4.4895, 'grad_norm': 2.9978508949279785, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.0}\n",
      "{'loss': 4.1299, 'grad_norm': 3.3809616565704346, 'learning_rate': 4.933333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 4.1238, 'grad_norm': 2.7193994522094727, 'learning_rate': 4.9166666666666665e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8742, 'grad_norm': 2.9090452194213867, 'learning_rate': 4.9e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8484, 'grad_norm': 2.881465196609497, 'learning_rate': 4.883333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7514, 'grad_norm': 2.9254953861236572, 'learning_rate': 4.866666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 3.641, 'grad_norm': 3.1974213123321533, 'learning_rate': 4.85e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7248, 'grad_norm': 3.376181125640869, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6756, 'grad_norm': 3.6174933910369873, 'learning_rate': 4.8166666666666674e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8541, 'grad_norm': 3.8623831272125244, 'learning_rate': 4.8e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6189, 'grad_norm': 3.4656879901885986, 'learning_rate': 4.7833333333333335e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7365, 'grad_norm': 4.396247386932373, 'learning_rate': 4.766666666666667e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6902, 'grad_norm': 3.5867438316345215, 'learning_rate': 4.75e-05, 'epoch': 0.01}\n",
      "{'loss': 3.7475, 'grad_norm': 3.869521379470825, 'learning_rate': 4.7333333333333336e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5797, 'grad_norm': 4.081594467163086, 'learning_rate': 4.716666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5789, 'grad_norm': 4.306498050689697, 'learning_rate': 4.7e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5557, 'grad_norm': 4.772358417510986, 'learning_rate': 4.683333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5787, 'grad_norm': 4.4740214347839355, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5545, 'grad_norm': 4.922819137573242, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6473, 'grad_norm': 4.0853729248046875, 'learning_rate': 4.633333333333333e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6121, 'grad_norm': 4.6947712898254395, 'learning_rate': 4.6166666666666666e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5113, 'grad_norm': 4.486271381378174, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4805, 'grad_norm': 5.357932090759277, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6035, 'grad_norm': 5.259058952331543, 'learning_rate': 4.566666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.549, 'grad_norm': 5.36110782623291, 'learning_rate': 4.55e-05, 'epoch': 0.01}\n",
      "{'loss': 3.617, 'grad_norm': 4.52680778503418, 'learning_rate': 4.5333333333333335e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6303, 'grad_norm': 4.741743087768555, 'learning_rate': 4.516666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5391, 'grad_norm': 5.722049236297607, 'learning_rate': 4.5e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4682, 'grad_norm': 5.309174060821533, 'learning_rate': 4.483333333333333e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6092, 'grad_norm': 5.698827266693115, 'learning_rate': 4.466666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.417, 'grad_norm': 5.236504077911377, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4945, 'grad_norm': 5.291338920593262, 'learning_rate': 4.433333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5201, 'grad_norm': 5.562943458557129, 'learning_rate': 4.4166666666666665e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5775, 'grad_norm': 5.221925258636475, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3627, 'grad_norm': 4.83976411819458, 'learning_rate': 4.383333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5336, 'grad_norm': 5.1612868309021, 'learning_rate': 4.3666666666666666e-05, 'epoch': 0.01}\n",
      "{'loss': 3.525, 'grad_norm': 5.22654914855957, 'learning_rate': 4.35e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4727, 'grad_norm': 5.595477104187012, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6936, 'grad_norm': 5.435100078582764, 'learning_rate': 4.316666666666667e-05, 'epoch': 0.01}\n",
      "{'loss': 3.498, 'grad_norm': 5.103206634521484, 'learning_rate': 4.3e-05, 'epoch': 0.01}\n",
      "{'loss': 3.624, 'grad_norm': 5.5724077224731445, 'learning_rate': 4.2833333333333335e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4186, 'grad_norm': 6.501977920532227, 'learning_rate': 4.266666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4213, 'grad_norm': 6.072294235229492, 'learning_rate': 4.25e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4285, 'grad_norm': 5.566120147705078, 'learning_rate': 4.233333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5328, 'grad_norm': 5.598531246185303, 'learning_rate': 4.216666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.448, 'grad_norm': 7.048577785491943, 'learning_rate': 4.2e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4557, 'grad_norm': 5.786890029907227, 'learning_rate': 4.183333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.565, 'grad_norm': 5.971183776855469, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.02}\n",
      " 17%|██████▋                                 | 500/3000 [05:48<32:11,  1.29it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.81s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:06<00:02,  2.25s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:21<00:00,  6.94s/it]\u001b[ABuilding prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.345 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "                                                                                \n",
      "\u001b[A{'eval_rouge-1': 31.322816, 'eval_rouge-2': 6.509672, 'eval_rouge-l': 24.584289999999996, 'eval_bleu-4': 0.031097722552126374, 'eval_runtime': 40.7481, 'eval_samples_per_second': 1.227, 'eval_steps_per_second': 0.098, 'epoch': 0.02}\n",
      " 17%|██████▋                                 | 500/3000 [06:29<32:11,  1.29it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:21<00:00,  6.94s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-500\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /home/liyongliang/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/ - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.324, 'grad_norm': 5.726175308227539, 'learning_rate': 4.15e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5457, 'grad_norm': 6.543201446533203, 'learning_rate': 4.133333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5877, 'grad_norm': 5.985097885131836, 'learning_rate': 4.116666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4863, 'grad_norm': 5.394625186920166, 'learning_rate': 4.1e-05, 'epoch': 0.02}\n",
      "{'loss': 3.526, 'grad_norm': 5.2890448570251465, 'learning_rate': 4.0833333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.649, 'grad_norm': 5.654748439788818, 'learning_rate': 4.066666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4924, 'grad_norm': 5.770187854766846, 'learning_rate': 4.05e-05, 'epoch': 0.02}\n",
      "{'loss': 3.374, 'grad_norm': 5.559588432312012, 'learning_rate': 4.0333333333333336e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4281, 'grad_norm': 6.143863677978516, 'learning_rate': 4.016666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4953, 'grad_norm': 6.387266635894775, 'learning_rate': 4e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4424, 'grad_norm': 6.213645935058594, 'learning_rate': 3.983333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4566, 'grad_norm': 6.634672164916992, 'learning_rate': 3.966666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4488, 'grad_norm': 5.89901876449585, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4596, 'grad_norm': 6.181870937347412, 'learning_rate': 3.933333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5314, 'grad_norm': 5.9626593589782715, 'learning_rate': 3.9166666666666665e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4836, 'grad_norm': 6.210232257843018, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.02}\n",
      "{'loss': 3.543, 'grad_norm': 6.150547027587891, 'learning_rate': 3.883333333333333e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3092, 'grad_norm': 6.9394731521606445, 'learning_rate': 3.866666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.4004, 'grad_norm': 6.568508148193359, 'learning_rate': 3.85e-05, 'epoch': 0.02}\n",
      "{'loss': 3.3551, 'grad_norm': 6.195523738861084, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5035, 'grad_norm': 7.070745944976807, 'learning_rate': 3.816666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5334, 'grad_norm': 6.72959041595459, 'learning_rate': 3.8e-05, 'epoch': 0.03}\n",
      "{'loss': 3.248, 'grad_norm': 6.907820701599121, 'learning_rate': 3.7833333333333336e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5717, 'grad_norm': 5.7469940185546875, 'learning_rate': 3.766666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3963, 'grad_norm': 6.4243574142456055, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4801, 'grad_norm': 6.070047378540039, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.626, 'grad_norm': 6.409261226654053, 'learning_rate': 3.7166666666666664e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4729, 'grad_norm': 6.247080326080322, 'learning_rate': 3.7e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3264, 'grad_norm': 6.493885517120361, 'learning_rate': 3.683333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5549, 'grad_norm': 6.841731071472168, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2891, 'grad_norm': 6.415126323699951, 'learning_rate': 3.65e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3611, 'grad_norm': 6.52009916305542, 'learning_rate': 3.633333333333333e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4594, 'grad_norm': 7.016907215118408, 'learning_rate': 3.6166666666666674e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4068, 'grad_norm': 6.362646579742432, 'learning_rate': 3.6e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5094, 'grad_norm': 6.147709846496582, 'learning_rate': 3.5833333333333335e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5355, 'grad_norm': 6.293789863586426, 'learning_rate': 3.566666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2939, 'grad_norm': 7.076960563659668, 'learning_rate': 3.55e-05, 'epoch': 0.03}\n",
      "{'loss': 3.493, 'grad_norm': 6.731359004974365, 'learning_rate': 3.5333333333333336e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4518, 'grad_norm': 7.5201849937438965, 'learning_rate': 3.516666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.2643, 'grad_norm': 7.850831031799316, 'learning_rate': 3.5e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4609, 'grad_norm': 7.798069000244141, 'learning_rate': 3.483333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4164, 'grad_norm': 6.967230796813965, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4611, 'grad_norm': 7.345279693603516, 'learning_rate': 3.45e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5744, 'grad_norm': 7.253223419189453, 'learning_rate': 3.433333333333333e-05, 'epoch': 0.03}\n",
      "{'loss': 3.366, 'grad_norm': 6.546604633331299, 'learning_rate': 3.4166666666666666e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4352, 'grad_norm': 8.01536750793457, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.03}\n",
      "{'loss': 3.5383, 'grad_norm': 5.919678211212158, 'learning_rate': 3.3833333333333334e-05, 'epoch': 0.03}\n",
      "{'loss': 3.3262, 'grad_norm': 7.035505771636963, 'learning_rate': 3.366666666666667e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4611, 'grad_norm': 7.276048183441162, 'learning_rate': 3.35e-05, 'epoch': 0.03}\n",
      "{'loss': 3.401, 'grad_norm': 7.793182849884033, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.03}\n",
      " 33%|█████████████                          | 1000/3000 [12:16<24:00,  1.39it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.40s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.87s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.903304000000002, 'eval_rouge-2': 6.594002000000001, 'eval_rouge-l': 25.613470000000003, 'eval_bleu-4': 0.032510091864972494, 'eval_runtime': 10.3791, 'eval_samples_per_second': 4.817, 'eval_steps_per_second': 0.385, 'epoch': 0.03}\n",
      " 33%|█████████████                          | 1000/3000 [12:27<24:00,  1.39it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:07<00:00,  1.82s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-1000\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /home/liyongliang/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/ - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.4506, 'grad_norm': 6.871498107910156, 'learning_rate': 3.316666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4588, 'grad_norm': 7.382968902587891, 'learning_rate': 3.3e-05, 'epoch': 0.04}\n",
      "{'loss': 3.6537, 'grad_norm': 8.1498441696167, 'learning_rate': 3.283333333333333e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4037, 'grad_norm': 6.482954502105713, 'learning_rate': 3.266666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3908, 'grad_norm': 8.767977714538574, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3561, 'grad_norm': 7.644168853759766, 'learning_rate': 3.233333333333333e-05, 'epoch': 0.04}\n",
      "{'loss': 3.39, 'grad_norm': 7.175603866577148, 'learning_rate': 3.2166666666666665e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4648, 'grad_norm': 7.32208251953125, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.04}\n",
      "{'loss': 3.5264, 'grad_norm': 7.102872371673584, 'learning_rate': 3.183333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.467, 'grad_norm': 6.565837860107422, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3363, 'grad_norm': 6.810915470123291, 'learning_rate': 3.15e-05, 'epoch': 0.04}\n",
      "{'loss': 3.5281, 'grad_norm': 7.783297061920166, 'learning_rate': 3.1333333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4373, 'grad_norm': 7.32282829284668, 'learning_rate': 3.116666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3635, 'grad_norm': 8.081515312194824, 'learning_rate': 3.1e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3219, 'grad_norm': 7.5958428382873535, 'learning_rate': 3.0833333333333335e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3602, 'grad_norm': 7.184376239776611, 'learning_rate': 3.066666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4525, 'grad_norm': 6.8379950523376465, 'learning_rate': 3.05e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4748, 'grad_norm': 6.44391393661499, 'learning_rate': 3.0333333333333337e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3596, 'grad_norm': 6.7195611000061035, 'learning_rate': 3.016666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4123, 'grad_norm': 6.399141788482666, 'learning_rate': 3e-05, 'epoch': 0.04}\n",
      "{'loss': 3.2475, 'grad_norm': 6.725387096405029, 'learning_rate': 2.9833333333333335e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3406, 'grad_norm': 7.423839569091797, 'learning_rate': 2.9666666666666672e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3787, 'grad_norm': 7.391969680786133, 'learning_rate': 2.95e-05, 'epoch': 0.04}\n",
      "{'loss': 3.375, 'grad_norm': 7.881082534790039, 'learning_rate': 2.9333333333333336e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4451, 'grad_norm': 6.810804843902588, 'learning_rate': 2.916666666666667e-05, 'epoch': 0.04}\n",
      "{'loss': 3.2838, 'grad_norm': 7.500702381134033, 'learning_rate': 2.9e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4609, 'grad_norm': 7.142116069793701, 'learning_rate': 2.8833333333333334e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3338, 'grad_norm': 7.380836009979248, 'learning_rate': 2.8666666666666668e-05, 'epoch': 0.04}\n",
      "{'loss': 3.3902, 'grad_norm': 6.99757194519043, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4855, 'grad_norm': 7.351690292358398, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4641, 'grad_norm': 6.943727016448975, 'learning_rate': 2.816666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4564, 'grad_norm': 6.745953559875488, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4029, 'grad_norm': 11.01719856262207, 'learning_rate': 2.7833333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3051, 'grad_norm': 7.452667713165283, 'learning_rate': 2.7666666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3531, 'grad_norm': 7.490620136260986, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2998, 'grad_norm': 7.974696159362793, 'learning_rate': 2.733333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.515, 'grad_norm': 7.66121244430542, 'learning_rate': 2.716666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.384, 'grad_norm': 7.077244281768799, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3645, 'grad_norm': 7.17390251159668, 'learning_rate': 2.6833333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4148, 'grad_norm': 6.599014759063721, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3504, 'grad_norm': 7.4602155685424805, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 3.268, 'grad_norm': 7.690630912780762, 'learning_rate': 2.633333333333333e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3805, 'grad_norm': 7.612826347351074, 'learning_rate': 2.6166666666666668e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3633, 'grad_norm': 7.180289268493652, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.05}\n",
      "{'loss': 3.2717, 'grad_norm': 6.899044513702393, 'learning_rate': 2.5833333333333336e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3984, 'grad_norm': 7.305251121520996, 'learning_rate': 2.5666666666666666e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4377, 'grad_norm': 9.045981407165527, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3023, 'grad_norm': 6.703607082366943, 'learning_rate': 2.5333333333333337e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4395, 'grad_norm': 7.473260879516602, 'learning_rate': 2.5166666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4539, 'grad_norm': 6.916137218475342, 'learning_rate': 2.5e-05, 'epoch': 0.05}\n",
      " 50%|███████████████████▌                   | 1500/3000 [18:14<15:43,  1.59it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.69s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:21<00:08,  8.40s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.756684, 'eval_rouge-2': 6.76875, 'eval_rouge-l': 24.593656000000006, 'eval_bleu-4': 0.03134031142743361, 'eval_runtime': 42.149, 'eval_samples_per_second': 1.186, 'eval_steps_per_second': 0.095, 'epoch': 0.05}\n",
      " 50%|███████████████████▌                   | 1500/3000 [18:56<15:43,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:23<00:00,  6.03s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-1500\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /home/liyongliang/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/ - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3422, 'grad_norm': 6.799837589263916, 'learning_rate': 2.4833333333333335e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3928, 'grad_norm': 8.252528190612793, 'learning_rate': 2.466666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4436, 'grad_norm': 8.252005577087402, 'learning_rate': 2.45e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4076, 'grad_norm': 7.274943828582764, 'learning_rate': 2.4333333333333336e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4957, 'grad_norm': 7.339188098907471, 'learning_rate': 2.4166666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4039, 'grad_norm': 8.246676445007324, 'learning_rate': 2.4e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4711, 'grad_norm': 7.956228256225586, 'learning_rate': 2.3833333333333334e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4357, 'grad_norm': 7.605582237243652, 'learning_rate': 2.3666666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5041, 'grad_norm': 9.155496597290039, 'learning_rate': 2.35e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3904, 'grad_norm': 6.982934474945068, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3674, 'grad_norm': 8.04015064239502, 'learning_rate': 2.3166666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3664, 'grad_norm': 8.458403587341309, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.468, 'grad_norm': 7.265200138092041, 'learning_rate': 2.2833333333333334e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3201, 'grad_norm': 8.040814399719238, 'learning_rate': 2.2666666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3719, 'grad_norm': 7.668686866760254, 'learning_rate': 2.25e-05, 'epoch': 0.06}\n",
      "{'loss': 3.307, 'grad_norm': 7.028544902801514, 'learning_rate': 2.2333333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4801, 'grad_norm': 8.634645462036133, 'learning_rate': 2.216666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3703, 'grad_norm': 7.311065673828125, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3748, 'grad_norm': 7.428864002227783, 'learning_rate': 2.1833333333333333e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5182, 'grad_norm': 6.9825968742370605, 'learning_rate': 2.1666666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4627, 'grad_norm': 7.285552978515625, 'learning_rate': 2.15e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5043, 'grad_norm': 7.478830814361572, 'learning_rate': 2.1333333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4066, 'grad_norm': 7.3686089515686035, 'learning_rate': 2.116666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4002, 'grad_norm': 7.459518909454346, 'learning_rate': 2.1e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4688, 'grad_norm': 7.44303560256958, 'learning_rate': 2.0833333333333336e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4523, 'grad_norm': 8.041227340698242, 'learning_rate': 2.0666666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3623, 'grad_norm': 8.286763191223145, 'learning_rate': 2.05e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3492, 'grad_norm': 8.270161628723145, 'learning_rate': 2.0333333333333334e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3936, 'grad_norm': 8.223434448242188, 'learning_rate': 2.0166666666666668e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3393, 'grad_norm': 7.699361801147461, 'learning_rate': 2e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3793, 'grad_norm': 8.964160919189453, 'learning_rate': 1.9833333333333335e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3439, 'grad_norm': 7.725287437438965, 'learning_rate': 1.9666666666666666e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5824, 'grad_norm': 7.873100757598877, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 3.348, 'grad_norm': 8.51554012298584, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4963, 'grad_norm': 9.077946662902832, 'learning_rate': 1.9166666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3775, 'grad_norm': 7.353550910949707, 'learning_rate': 1.9e-05, 'epoch': 0.06}\n",
      "{'loss': 3.3236, 'grad_norm': 8.197270393371582, 'learning_rate': 1.8833333333333335e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3072, 'grad_norm': 7.4287567138671875, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3977, 'grad_norm': 7.319246292114258, 'learning_rate': 1.85e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3736, 'grad_norm': 8.002217292785645, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3965, 'grad_norm': 8.050604820251465, 'learning_rate': 1.8166666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4861, 'grad_norm': 7.40885591506958, 'learning_rate': 1.8e-05, 'epoch': 0.07}\n",
      "{'loss': 3.284, 'grad_norm': 7.827249526977539, 'learning_rate': 1.7833333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5012, 'grad_norm': 7.6251044273376465, 'learning_rate': 1.7666666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3615, 'grad_norm': 6.996486663818359, 'learning_rate': 1.75e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2891, 'grad_norm': 8.757014274597168, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3703, 'grad_norm': 7.802682876586914, 'learning_rate': 1.7166666666666666e-05, 'epoch': 0.07}\n",
      "{'loss': 3.24, 'grad_norm': 7.61399507522583, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4234, 'grad_norm': 7.125622749328613, 'learning_rate': 1.6833333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4699, 'grad_norm': 7.885618686676025, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.07}\n",
      " 67%|██████████████████████████             | 2000/3000 [24:32<10:57,  1.52it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:04<00:04,  2.05s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:08<00:02,  2.83s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.16389, 'eval_rouge-2': 7.134302, 'eval_rouge-l': 24.563896, 'eval_bleu-4': 0.03400371868473542, 'eval_runtime': 28.6612, 'eval_samples_per_second': 1.745, 'eval_steps_per_second': 0.14, 'epoch': 0.07}\n",
      " 67%|██████████████████████████             | 2000/3000 [25:00<10:57,  1.52it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:10<00:00,  2.62s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-2000\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /home/liyongliang/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/ - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3896, 'grad_norm': 8.888087272644043, 'learning_rate': 1.65e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4994, 'grad_norm': 7.213908672332764, 'learning_rate': 1.6333333333333335e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5564, 'grad_norm': 8.900900840759277, 'learning_rate': 1.6166666666666665e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4937, 'grad_norm': 8.5537109375, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3705, 'grad_norm': 8.244245529174805, 'learning_rate': 1.5833333333333333e-05, 'epoch': 0.07}\n",
      "{'loss': 3.327, 'grad_norm': 7.768511772155762, 'learning_rate': 1.5666666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4486, 'grad_norm': 8.297331809997559, 'learning_rate': 1.55e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4219, 'grad_norm': 8.263960838317871, 'learning_rate': 1.5333333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4457, 'grad_norm': 7.589245796203613, 'learning_rate': 1.5166666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3611, 'grad_norm': 7.753732204437256, 'learning_rate': 1.5e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2977, 'grad_norm': 7.6129865646362305, 'learning_rate': 1.4833333333333336e-05, 'epoch': 0.07}\n",
      "{'loss': 3.5838, 'grad_norm': 7.869486331939697, 'learning_rate': 1.4666666666666668e-05, 'epoch': 0.07}\n",
      "{'loss': 3.2582, 'grad_norm': 7.626529693603516, 'learning_rate': 1.45e-05, 'epoch': 0.07}\n",
      "{'loss': 3.3643, 'grad_norm': 8.405789375305176, 'learning_rate': 1.4333333333333334e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4068, 'grad_norm': 7.387852191925049, 'learning_rate': 1.4166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.5223, 'grad_norm': 8.132198333740234, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3965, 'grad_norm': 6.763648509979248, 'learning_rate': 1.3833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4176, 'grad_norm': 8.039749145507812, 'learning_rate': 1.3666666666666666e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3529, 'grad_norm': 7.656770706176758, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4379, 'grad_norm': 7.346511363983154, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4518, 'grad_norm': 6.896786212921143, 'learning_rate': 1.3166666666666665e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4199, 'grad_norm': 7.752607822418213, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4186, 'grad_norm': 8.056241989135742, 'learning_rate': 1.2833333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3715, 'grad_norm': 8.407922744750977, 'learning_rate': 1.2666666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2395, 'grad_norm': 8.529703140258789, 'learning_rate': 1.25e-05, 'epoch': 0.08}\n",
      "{'loss': 3.368, 'grad_norm': 7.92634916305542, 'learning_rate': 1.2333333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4316, 'grad_norm': 8.82873249053955, 'learning_rate': 1.2166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.468, 'grad_norm': 7.7057271003723145, 'learning_rate': 1.2e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2947, 'grad_norm': 8.423534393310547, 'learning_rate': 1.1833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3578, 'grad_norm': 8.407553672790527, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3275, 'grad_norm': 8.503982543945312, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3258, 'grad_norm': 8.417531967163086, 'learning_rate': 1.1333333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3666, 'grad_norm': 8.927351951599121, 'learning_rate': 1.1166666666666668e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3643, 'grad_norm': 7.69622802734375, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2752, 'grad_norm': 8.639667510986328, 'learning_rate': 1.0833333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3789, 'grad_norm': 8.353511810302734, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3604, 'grad_norm': 7.931366443634033, 'learning_rate': 1.05e-05, 'epoch': 0.08}\n",
      "{'loss': 3.498, 'grad_norm': 8.54247760772705, 'learning_rate': 1.0333333333333333e-05, 'epoch': 0.08}\n",
      "{'loss': 3.2367, 'grad_norm': 8.481965065002441, 'learning_rate': 1.0166666666666667e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4615, 'grad_norm': 7.81195068359375, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4572, 'grad_norm': 8.279252052307129, 'learning_rate': 9.833333333333333e-06, 'epoch': 0.08}\n",
      "{'loss': 3.2811, 'grad_norm': 7.9599127769470215, 'learning_rate': 9.666666666666667e-06, 'epoch': 0.08}\n",
      "{'loss': 3.3711, 'grad_norm': 7.432910919189453, 'learning_rate': 9.5e-06, 'epoch': 0.08}\n",
      "{'loss': 3.383, 'grad_norm': 8.020474433898926, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2756, 'grad_norm': 7.804571151733398, 'learning_rate': 9.166666666666666e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3139, 'grad_norm': 7.852153301239014, 'learning_rate': 9e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2625, 'grad_norm': 8.94565486907959, 'learning_rate': 8.833333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4373, 'grad_norm': 7.551792621612549, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4717, 'grad_norm': 7.814210891723633, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3951, 'grad_norm': 9.444375038146973, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.09}\n",
      " 83%|████████████████████████████████▌      | 2500/3000 [30:41<05:36,  1.49it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.95s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:06<00:02,  2.34s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 32.626118000000005, 'eval_rouge-2': 7.547896000000001, 'eval_rouge-l': 25.150626, 'eval_bleu-4': 0.035826496435269514, 'eval_runtime': 27.8299, 'eval_samples_per_second': 1.797, 'eval_steps_per_second': 0.144, 'epoch': 0.09}\n",
      " 83%|████████████████████████████████▌      | 2500/3000 [31:09<05:36,  1.49it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:08<00:00,  2.21s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-2500\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /home/liyongliang/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/ - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 3.3061, 'grad_norm': 8.487200736999512, 'learning_rate': 8.166666666666668e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3402, 'grad_norm': 9.878190994262695, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2455, 'grad_norm': 8.06669807434082, 'learning_rate': 7.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3951, 'grad_norm': 8.22714614868164, 'learning_rate': 7.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3961, 'grad_norm': 7.830958843231201, 'learning_rate': 7.5e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4049, 'grad_norm': 8.480363845825195, 'learning_rate': 7.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4715, 'grad_norm': 8.082115173339844, 'learning_rate': 7.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4773, 'grad_norm': 8.554299354553223, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3797, 'grad_norm': 8.490832328796387, 'learning_rate': 6.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4832, 'grad_norm': 8.674680709838867, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3588, 'grad_norm': 8.006664276123047, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4266, 'grad_norm': 7.799664497375488, 'learning_rate': 6.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.5287, 'grad_norm': 7.746098518371582, 'learning_rate': 6.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4438, 'grad_norm': 8.620875358581543, 'learning_rate': 6e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4084, 'grad_norm': 8.09919261932373, 'learning_rate': 5.833333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.352, 'grad_norm': 8.044451713562012, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4139, 'grad_norm': 8.674003601074219, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2701, 'grad_norm': 7.554014682769775, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4766, 'grad_norm': 8.682518005371094, 'learning_rate': 5.166666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4504, 'grad_norm': 8.862707138061523, 'learning_rate': 5e-06, 'epoch': 0.09}\n",
      "{'loss': 3.4289, 'grad_norm': 8.523527145385742, 'learning_rate': 4.833333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 3.2535, 'grad_norm': 7.697203636169434, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 3.3797, 'grad_norm': 8.06981372833252, 'learning_rate': 4.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.39, 'grad_norm': 8.05002498626709, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4602, 'grad_norm': 8.864839553833008, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3984, 'grad_norm': 8.128521919250488, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3498, 'grad_norm': 8.210118293762207, 'learning_rate': 3.833333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2625, 'grad_norm': 8.6415433883667, 'learning_rate': 3.666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2807, 'grad_norm': 8.269469261169434, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2473, 'grad_norm': 7.728572368621826, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4479, 'grad_norm': 7.877887725830078, 'learning_rate': 3.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3793, 'grad_norm': 8.102330207824707, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3941, 'grad_norm': 8.130993843078613, 'learning_rate': 2.8333333333333335e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4434, 'grad_norm': 9.247008323669434, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.4082, 'grad_norm': 8.701950073242188, 'learning_rate': 2.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3436, 'grad_norm': 8.468864440917969, 'learning_rate': 2.3333333333333336e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3732, 'grad_norm': 8.621682167053223, 'learning_rate': 2.166666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.5078, 'grad_norm': 9.065587997436523, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3035, 'grad_norm': 8.025314331054688, 'learning_rate': 1.8333333333333335e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3297, 'grad_norm': 9.210480690002441, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3109, 'grad_norm': 8.012495994567871, 'learning_rate': 1.5e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2494, 'grad_norm': 7.312704086303711, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3625, 'grad_norm': 8.815743446350098, 'learning_rate': 1.1666666666666668e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2572, 'grad_norm': 8.41528034210205, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.1}\n",
      "{'loss': 3.3834, 'grad_norm': 8.07083511352539, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.1}\n",
      "{'loss': 3.2131, 'grad_norm': 8.966815948486328, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.1}\n",
      "{'loss': 3.4475, 'grad_norm': 8.891422271728516, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.1}\n",
      "{'loss': 3.4367, 'grad_norm': 9.0366792678833, 'learning_rate': 3.3333333333333335e-07, 'epoch': 0.1}\n",
      "{'loss': 3.4758, 'grad_norm': 8.136100769042969, 'learning_rate': 1.6666666666666668e-07, 'epoch': 0.1}\n",
      "{'loss': 3.3715, 'grad_norm': 7.802977561950684, 'learning_rate': 0.0, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [36:59<00:00,  1.52it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.98s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:22<00:08,  8.97s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_rouge-1': 31.800968, 'eval_rouge-2': 7.149132, 'eval_rouge-l': 24.36075, 'eval_bleu-4': 0.03339704340363245, 'eval_runtime': 44.055, 'eval_samples_per_second': 1.135, 'eval_steps_per_second': 0.091, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [37:43<00:00,  1.52it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  6.44s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./output/checkpoint-3000\n",
      "/home/liyongliang/miniconda3/envs/glm/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /home/liyongliang/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/ - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 2263.9098, 'train_samples_per_second': 5.301, 'train_steps_per_second': 1.325, 'train_loss': 3.448099609375, 'epoch': 0.1}\n",
      "100%|███████████████████████████████████████| 3000/3000 [37:43<00:00,  1.33it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1070\n",
      "  Batch size = 16\n",
      "100%|███████████████████████████████████████████| 67/67 [13:51<00:00, 12.41s/it]\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python3 finetune_hf.py  data/AdvertiseGen_fix  ~/.cache/modelscope/hub/ZhipuAI/chatglm3-6b/  configs/lora.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9418f6c5c264601",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3. 使用微调的数据集进行推理\n",
    "在完成微调任务之后，我们可以查看到 `output` 文件夹下多了很多个`checkpoint-*`的文件夹，这些文件夹代表了训练的轮数。\n",
    "我们选择最后一轮的微调权重，并使用inference进行导入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f22b735175e1c0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T05:51:18.377240Z",
     "start_time": "2024-04-07T05:51:18.269219Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-1000  checkpoint-2000  checkpoint-3000\n",
      "checkpoint-1500  checkpoint-2500  checkpoint-500\n"
     ]
    }
   ],
   "source": [
    "!ls output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5060015c24e97ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T05:51:19.277953Z",
     "start_time": "2024-04-07T05:51:19.165655Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:11<00:00,  1.69s/it]\n",
      "这款连衣裙是套头式的设计，简单实穿，拉链式的袖口设计，方便穿脱。压褶的百褶裙摆，不规则的层次感，遮肉显瘦，凸显性感。拼接的网纱设计，增加了层次感，凸显个性。木耳边的设计，提升气质，尽显女人味。\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0  python3 inference_hf.py output/checkpoint-3000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd83087f096094",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. 总结\n",
    "到此位置，我们就完成了使用单张 GPU Lora 来微调 ChatGLM3-6B 模型，使其能生产出更好的广告。\n",
    "在本章节中，你将会学会：\n",
    "+ 如何使用模型进行 Lora 微调\n",
    "+ 微调数据集的准备和对齐\n",
    "+ 使用微调的模型进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43859eff3085c954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
